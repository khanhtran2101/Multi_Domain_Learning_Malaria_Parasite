{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4ee631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:51:00.470536Z",
     "iopub.status.busy": "2024-11-22T02:51:00.470197Z",
     "iopub.status.idle": "2024-11-22T02:54:32.303988Z",
     "shell.execute_reply": "2024-11-22T02:54:32.303026Z"
    },
    "papermill": {
     "duration": 211.839417,
     "end_time": "2024-11-22T02:54:32.305989",
     "exception": false,
     "start_time": "2024-11-22T02:51:00.466572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.1.2\r\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (2024.6.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\r\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\r\n",
      "Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m128.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.4.0\r\n",
      "    Uninstalling torch-2.4.0:\r\n",
      "      Successfully uninstalled torch-2.4.0\r\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 triton-2.1.0\r\n",
      "Collecting torchvision==0.16.2\r\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (2.32.3)\r\n",
      "Requirement already satisfied: torch==2.1.2 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (2.1.2)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (10.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->torchvision==0.16.2) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchvision==0.16.2) (12.6.85)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (2024.8.30)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision==0.16.2) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision==0.16.2) (1.3.0)\r\n",
      "Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torchvision\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.19.0\r\n",
      "    Uninstalling torchvision-0.19.0:\r\n",
      "      Successfully uninstalled torchvision-0.19.0\r\n",
      "Successfully installed torchvision-0.16.2\r\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.10/site-packages (1.26.4)\r\n",
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.7)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (2.2.2)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (24.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.32.3)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.7.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0.2)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.6)\r\n",
      "Collecting ordered-set (from model-index->openmim)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (3.20.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (4.66.4)\r\n",
      "Collecting openxlab (from opendatalab->openmim)\r\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2024.8.30)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2024.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\r\n",
      "Collecting filelock~=3.14.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting packaging~=24.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas->openmim)\r\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting requests (from openmim)\r\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting rich (from openmim)\r\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting tqdm (from opendatalab->openmim)\r\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\r\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: cryptography>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (42.0.8)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\r\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading openxlab-0.1.2-py3-none-any.whl (311 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\r\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core\r\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112372 sha256=3c5cac35185ea3853161a9b73aa11940ed272eaa7e6405d42fbf707b5da0d984\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535317 sha256=a9b3559d534b518ed2f6a2e8f2ee2b3c3d04a43cf04cd1567f61878ce064d29d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/11/5e/08e7cb4e03a3e83b4862edd12d1143c8d3936a3dd57a3ee46d\r\n",
      "Successfully built oss2 aliyun-python-sdk-core\r\n",
      "Installing collected packages: pytz, tqdm, setuptools, requests, packaging, ordered-set, jmespath, filelock, rich, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\r\n",
      "  Attempting uninstall: pytz\r\n",
      "    Found existing installation: pytz 2024.1\r\n",
      "    Uninstalling pytz-2024.1:\r\n",
      "      Successfully uninstalled pytz-2024.1\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.4\r\n",
      "    Uninstalling tqdm-4.66.4:\r\n",
      "      Successfully uninstalled tqdm-4.66.4\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 70.0.0\r\n",
      "    Uninstalling setuptools-70.0.0:\r\n",
      "      Successfully uninstalled setuptools-70.0.0\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.32.3\r\n",
      "    Uninstalling requests-2.32.3:\r\n",
      "      Successfully uninstalled requests-2.32.3\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.15.1\r\n",
      "    Uninstalling filelock-3.15.1:\r\n",
      "      Successfully uninstalled filelock-3.15.1\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 13.7.1\r\n",
      "    Uninstalling rich-13.7.1:\r\n",
      "      Successfully uninstalled rich-13.7.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.35.23 which is incompatible.\r\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "datasets 3.0.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 3.0.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-server 2.27.2 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 filelock-3.14.0 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.2 ordered-set-4.1.0 oss2-2.17.0 packaging-24.2 pytz-2023.4 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.10.5-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting addict (from mmengine)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0.2)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.4.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.10.0.84)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.18.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (7.0.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (3.11.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Downloading mmengine-0.10.5-py3-none-any.whl (452 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.3/452.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.10.5\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/index.html\r\n",
      "Collecting mmcv==2.1.0\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (94.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (0.10.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv==2.1.0) (4.10.0.84)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv==2.1.0) (3.7.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv==2.1.0) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv==2.1.0) (2.4.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv==2.1.0) (7.0.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv==2.1.0) (3.11.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv==2.1.0) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv==2.1.0) (3.19.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.1.0) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.1.0\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/index.html\r\n",
      "Collecting mmdet\r\n",
      "  Downloading mmdet-3.3.0-py3-none-any.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmdet) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.26.4)\r\n",
      "Collecting pycocotools (from mmdet)\r\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.14.1)\r\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.8.5.post1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from mmdet) (1.16.0)\r\n",
      "Collecting terminaltables (from mmdet)\r\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mmdet) (4.65.2)\r\n",
      "Requirement already satisfied: mmcv<2.2.0,>=2.0.0rc4 in /opt/conda/lib/python3.10/site-packages (from mmdet) (2.1.0)\r\n",
      "Requirement already satisfied: mmengine<1.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from mmdet) (0.10.5)\r\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (2.4.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (4.10.0.84)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine<1.0.0,>=0.7.1->mmdet) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine<1.0.0,>=0.7.1->mmdet) (2.4.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet) (2.18.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (7.0.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (3.11.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (3.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.0.0,>=0.7.1->mmdet) (0.1.2)\r\n",
      "Downloading mmdet-3.3.0-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: terminaltables, pycocotools, mmdet\r\n",
      "Successfully installed mmdet-3.3.0 pycocotools-2.0.8 terminaltables-3.1.10\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.2\n",
    "!pip install torchvision==0.16.2\n",
    "!pip install numpy==1.26.4\n",
    "!pip install openmim\n",
    "!mim install mmengine\n",
    "!mim install \"mmcv==2.1.0\"\n",
    "!mim install mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c4f67e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-11-22T02:54:32.390026Z",
     "iopub.status.busy": "2024-11-22T02:54:32.389700Z",
     "iopub.status.idle": "2024-11-22T02:54:51.446708Z",
     "shell.execute_reply": "2024-11-22T02:54:51.445437Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 19.101574,
     "end_time": "2024-11-22T02:54:51.449515",
     "exception": false,
     "start_time": "2024-11-22T02:54:32.347941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Multi_Domain_Learning_Malaria_Parasite'...\r\n",
      "remote: Enumerating objects: 16775, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (214/214), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (152/152), done.\u001b[K\r\n",
      "remote: Total 16775 (delta 99), reused 140 (delta 60), pack-reused 16561 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (16775/16775), 13.58 MiB | 28.32 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11683/11683), done.\r\n",
      "/kaggle/working/Multi_Domain_Learning_Malaria_Parasite\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/index.html\r\n",
      "Obtaining file:///kaggle/working/Multi_Domain_Learning_Malaria_Parasite\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting einops (from mmpretrain==1.2.0)\r\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from mmpretrain==1.2.0) (7.0.0)\r\n",
      "Collecting mat4py (from mmpretrain==1.2.0)\r\n",
      "  Downloading mat4py-0.6.0-py2.py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmpretrain==1.2.0) (3.7.5)\r\n",
      "Collecting modelindex (from mmpretrain==1.2.0)\r\n",
      "  Downloading modelindex-0.0.2-py3-none-any.whl.metadata (756 bytes)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmpretrain==1.2.0) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmpretrain==1.2.0) (13.4.2)\r\n",
      "Requirement already satisfied: mmcv<2.4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from mmpretrain==1.2.0) (2.1.0)\r\n",
      "Requirement already satisfied: mmengine<1.0.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from mmpretrain==1.2.0) (0.10.5)\r\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (2.4.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (4.10.0.84)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine<1.0.0,>=0.8.3->mmpretrain==1.2.0) (2.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->mmpretrain==1.2.0) (3.19.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmpretrain==1.2.0) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmpretrain==1.2.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmpretrain==1.2.0) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmpretrain==1.2.0) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmpretrain==1.2.0) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmpretrain==1.2.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: model-index in /opt/conda/lib/python3.10/site-packages (from modelindex->mmpretrain==1.2.0) (0.1.11)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmpretrain==1.2.0) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmpretrain==1.2.0) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmpretrain==1.2.0) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmpretrain==1.2.0) (1.16.0)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->modelindex->mmpretrain==1.2.0) (3.6)\r\n",
      "Requirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->modelindex->mmpretrain==1.2.0) (4.1.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from model-index->modelindex->mmpretrain==1.2.0) (8.1.7)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (3.11.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv<2.4.0,>=2.0.0->mmpretrain==1.2.0) (2.0.1)\r\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mat4py-0.6.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\r\n",
      "Installing collected packages: mat4py, einops, modelindex, mmpretrain\r\n",
      "  Running setup.py develop for mmpretrain\r\n",
      "Successfully installed einops-0.8.0 mat4py-0.6.0 mmpretrain-1.2.0 modelindex-0.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/khanhtran2101/Multi_Domain_Learning_Malaria_Parasite\n",
    "%cd Multi_Domain_Learning_Malaria_Parasite\n",
    "!mim install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed07dd79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:54:51.538151Z",
     "iopub.status.busy": "2024-11-22T02:54:51.537804Z",
     "iopub.status.idle": "2024-11-22T04:57:12.545619Z",
     "shell.execute_reply": "2024-11-22T04:57:12.544538Z"
    },
    "papermill": {
     "duration": 7341.054694,
     "end_time": "2024-11-22T04:57:12.547827",
     "exception": false,
     "start_time": "2024-11-22T02:54:51.493133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "11/22 02:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1303620748\r\n",
      "    GPU 0: Tesla P100-PCIE-16GB\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.3, V12.3.107\r\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n",
      "    PyTorch: 2.1.2+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX512\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.2+cu121\r\n",
      "    OpenCV: 4.10.0\r\n",
      "    MMEngine: 0.10.5\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1303620748\r\n",
      "    deterministic: False\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "11/22 02:54:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=256)\r\n",
      "batch_size = 128\r\n",
      "data_root = '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(by_epoch=True, interval=10, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=100, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(enable=False, type='VisualizationHook'))\r\n",
      "default_scope = 'mmpretrain'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = None\r\n",
      "log_level = 'INFO'\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        depth=50,\r\n",
      "        init_cfg=dict(\r\n",
      "            checkpoint=\r\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth',\r\n",
      "            prefix='backbone',\r\n",
      "            type='Pretrained'),\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(3, ),\r\n",
      "        style='pytorch',\r\n",
      "        type='ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        to_rgb=True),\r\n",
      "    head=dict(\r\n",
      "        in_channels=2048,\r\n",
      "        loss=dict(loss_weight=1.0, type='FocalLoss'),\r\n",
      "        num_classes=6,\r\n",
      "        topk=(\r\n",
      "            1,\r\n",
      "            5,\r\n",
      "        ),\r\n",
      "        type='LinearClsHead'),\r\n",
      "    neck=dict(type='GlobalAveragePooling'),\r\n",
      "    type='ImageClassifier')\r\n",
      "optim_wrapper = dict(\r\n",
      "    clip_grad=None,\r\n",
      "    optimizer=dict(lr=0.0001, type='Adam', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "optimizer = dict(_delete_=True, lr=0.0001, type='Adam', weight_decay=0.0001)\r\n",
      "param_scheduler = dict(\r\n",
      "    by_epoch=True, gamma=0.1, milestones=[\r\n",
      "        25,\r\n",
      "    ], type='MultiStepLR')\r\n",
      "randomness = dict(deterministic=False, seed=None)\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=128,\r\n",
      "    collate_fn=dict(type='default_collate'),\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test_annotation.txt',\r\n",
      "        data_prefix='',\r\n",
      "        data_root=\r\n",
      "        '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(scale=224, type='Resize'),\r\n",
      "            dict(type='PackInputs'),\r\n",
      "        ],\r\n",
      "        type='CustomDataset',\r\n",
      "        with_label=True),\r\n",
      "    num_workers=1,\r\n",
      "    persistent_workers=True,\r\n",
      "    pin_memory=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "test_evaluator = [\r\n",
      "    dict(type='Accuracy'),\r\n",
      "    dict(type='ConfusionMatrix'),\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(scale=224, type='Resize'),\r\n",
      "    dict(type='PackInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=50, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_size=128,\r\n",
      "    collate_fn=dict(type='default_collate'),\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train_annotation.txt',\r\n",
      "        data_prefix='',\r\n",
      "        data_root=\r\n",
      "        '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                crop_ratio_range=(\r\n",
      "                    0.08,\r\n",
      "                    1.0,\r\n",
      "                ),\r\n",
      "                scale=224,\r\n",
      "                type='RandomResizedCrop'),\r\n",
      "            dict(\r\n",
      "                direction=[\r\n",
      "                    'horizontal',\r\n",
      "                    'vertical',\r\n",
      "                ],\r\n",
      "                prob=[\r\n",
      "                    0.25,\r\n",
      "                    0.25,\r\n",
      "                ],\r\n",
      "                type='RandomFlip'),\r\n",
      "            dict(type='PackInputs'),\r\n",
      "        ],\r\n",
      "        type='CustomDataset',\r\n",
      "        with_label=True),\r\n",
      "    num_workers=1,\r\n",
      "    persistent_workers=True,\r\n",
      "    pin_memory=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(crop_ratio_range=(\r\n",
      "        0.08,\r\n",
      "        1.0,\r\n",
      "    ), scale=224, type='RandomResizedCrop'),\r\n",
      "    dict(\r\n",
      "        direction=[\r\n",
      "            'horizontal',\r\n",
      "            'vertical',\r\n",
      "        ],\r\n",
      "        prob=[\r\n",
      "            0.25,\r\n",
      "            0.25,\r\n",
      "        ],\r\n",
      "        type='RandomFlip'),\r\n",
      "    dict(type='PackInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=128,\r\n",
      "    collate_fn=dict(type='default_collate'),\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val_annotation.txt',\r\n",
      "        data_prefix='',\r\n",
      "        data_root=\r\n",
      "        '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(scale=224, type='Resize'),\r\n",
      "            dict(type='PackInputs'),\r\n",
      "        ],\r\n",
      "        type='CustomDataset',\r\n",
      "        with_label=True),\r\n",
      "    num_workers=1,\r\n",
      "    persistent_workers=True,\r\n",
      "    pin_memory=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "val_evaluator = [\r\n",
      "    dict(type='Accuracy'),\r\n",
      "    dict(type='ConfusionMatrix'),\r\n",
      "]\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    type='Visualizer', vis_backends=[\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = '/kaggle/working/experiment_result'\r\n",
      "\r\n",
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "11/22 02:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "11/22 02:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) VisualizationHook                  \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) VisualizationHook                  \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "11/22 02:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load backbone in model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\r\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\r\n",
      "Downloading: \"https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_8xb32_in1k_20210831-ea4938fc.pth\r\n",
      "100%|██████████████████████████████████████| 97.8M/97.8M [00:03<00:00, 33.8MB/s]\r\n",
      "11/22 02:55:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\r\n",
      "11/22 02:55:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\r\n",
      "11/22 02:55:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working/experiment_result.\r\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\r\n",
      "  self.pid = os.fork()\r\n",
      "11/22 02:57:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/241]  lr: 1.0000e-04  eta: 3:58:14  time: 1.1332  data_time: 0.5499  memory: 10877  loss: 0.0219\r\n",
      "11/22 02:59:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/241]  lr: 1.0000e-04  eta: 4:01:38  time: 1.2687  data_time: 0.6851  memory: 10877  loss: 0.0228\r\n",
      "11/22 03:00:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/241]  lr: 1.0000e-04  eta: 3:21:15  time: 0.5852  data_time: 0.0012  memory: 10877  loss: 0.0192\r\n",
      "11/22 03:02:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][200/241]  lr: 1.0000e-04  eta: 2:59:57  time: 0.5851  data_time: 0.0013  memory: 10877  loss: 0.0241\r\n",
      "11/22 03:02:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/241]  lr: 1.0000e-04  eta: 2:41:45  time: 0.5848  data_time: 0.0012  memory: 10877  loss: 0.0224\r\n",
      "11/22 03:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][200/241]  lr: 1.0000e-04  eta: 2:33:05  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0307\r\n",
      "11/22 03:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/241]  lr: 1.0000e-04  eta: 2:24:00  time: 0.5849  data_time: 0.0013  memory: 10877  loss: 0.0246\r\n",
      "11/22 03:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][200/241]  lr: 1.0000e-04  eta: 2:19:00  time: 0.5850  data_time: 0.0012  memory: 10877  loss: 0.0163\r\n",
      "11/22 03:07:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:07:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:08:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/241]  lr: 1.0000e-04  eta: 2:13:13  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0197\r\n",
      "11/22 03:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][200/241]  lr: 1.0000e-04  eta: 2:09:47  time: 0.5851  data_time: 0.0011  memory: 10877  loss: 0.0198\r\n",
      "11/22 03:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][35/35]    accuracy/top1: 97.2581  confusion_matrix/result: \r\n",
      "tensor([[  46,    4,    1,    0,    1,    6],\r\n",
      "        [  21,   10,    1,    0,    0,    1],\r\n",
      "        [   0,    2,   25,    0,    0,    0],\r\n",
      "        [   0,    0,    4,   11,    1,    0],\r\n",
      "        [   1,    1,    0,    0, 4176,    4],\r\n",
      "        [   4,    1,    0,    0,   68,   24]])\r\n",
      "  data_time: 0.9749  time: 1.1553\r\n",
      "11/22 03:11:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/241]  lr: 1.0000e-04  eta: 2:05:34  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0172\r\n",
      "11/22 03:12:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][200/241]  lr: 1.0000e-04  eta: 2:02:56  time: 0.5851  data_time: 0.0012  memory: 10877  loss: 0.0245\r\n",
      "11/22 03:12:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:13:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/241]  lr: 1.0000e-04  eta: 1:59:34  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0222\r\n",
      "11/22 03:14:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][200/241]  lr: 1.0000e-04  eta: 1:57:23  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0225\r\n",
      "11/22 03:14:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/241]  lr: 1.0000e-04  eta: 1:54:32  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0188\r\n",
      "11/22 03:16:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][200/241]  lr: 1.0000e-04  eta: 1:52:40  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0230\r\n",
      "11/22 03:17:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/241]  lr: 1.0000e-04  eta: 1:50:12  time: 0.5853  data_time: 0.0013  memory: 10877  loss: 0.0211\r\n",
      "11/22 03:19:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][200/241]  lr: 1.0000e-04  eta: 1:48:31  time: 0.5853  data_time: 0.0011  memory: 10877  loss: 0.0201\r\n",
      "11/22 03:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/241]  lr: 1.0000e-04  eta: 1:46:15  time: 0.5847  data_time: 0.0011  memory: 10877  loss: 0.0161\r\n",
      "11/22 03:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][200/241]  lr: 1.0000e-04  eta: 1:44:42  time: 0.5847  data_time: 0.0011  memory: 10877  loss: 0.0180\r\n",
      "11/22 03:21:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:21:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\r\n",
      "11/22 03:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][35/35]    accuracy/top1: 97.2581  confusion_matrix/result: \r\n",
      "tensor([[  41,    8,    0,    0,    6,    3],\r\n",
      "        [   9,   23,    0,    0,    0,    1],\r\n",
      "        [   0,    2,   19,    5,    0,    1],\r\n",
      "        [   0,    0,    0,   16,    0,    0],\r\n",
      "        [   1,    0,    0,    0, 4181,    0],\r\n",
      "        [   2,    0,    0,    0,   83,   12]])\r\n",
      "  data_time: 0.0156  time: 0.1932\r\n",
      "11/22 03:23:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][100/241]  lr: 1.0000e-04  eta: 1:42:36  time: 0.5851  data_time: 0.0011  memory: 10877  loss: 0.0159\r\n",
      "11/22 03:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][200/241]  lr: 1.0000e-04  eta: 1:41:09  time: 0.5855  data_time: 0.0012  memory: 10877  loss: 0.0170\r\n",
      "11/22 03:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][100/241]  lr: 1.0000e-04  eta: 1:39:11  time: 0.5852  data_time: 0.0012  memory: 10877  loss: 0.0261\r\n",
      "11/22 03:26:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][200/241]  lr: 1.0000e-04  eta: 1:37:49  time: 0.5851  data_time: 0.0011  memory: 10877  loss: 0.0191\r\n",
      "11/22 03:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:27:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][100/241]  lr: 1.0000e-04  eta: 1:35:56  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0170\r\n",
      "11/22 03:27:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][200/241]  lr: 1.0000e-04  eta: 1:34:38  time: 0.5845  data_time: 0.0011  memory: 10877  loss: 0.0200\r\n",
      "11/22 03:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:30:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][100/241]  lr: 1.0000e-04  eta: 1:32:49  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0167\r\n",
      "11/22 03:31:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][200/241]  lr: 1.0000e-04  eta: 1:31:34  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0161\r\n",
      "11/22 03:31:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:32:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][100/241]  lr: 1.0000e-04  eta: 1:29:49  time: 0.5854  data_time: 0.0011  memory: 10877  loss: 0.0187\r\n",
      "11/22 03:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][200/241]  lr: 1.0000e-04  eta: 1:28:35  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0168\r\n",
      "11/22 03:33:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][35/35]    accuracy/top1: 97.7340  confusion_matrix/result: \r\n",
      "tensor([[  49,    8,    0,    0,    0,    1],\r\n",
      "        [  11,   21,    0,    0,    0,    1],\r\n",
      "        [   0,    3,   22,    2,    0,    0],\r\n",
      "        [   0,    0,    2,   14,    0,    0],\r\n",
      "        [   3,    0,    0,    0, 4176,    3],\r\n",
      "        [   5,    0,    0,    0,   61,   31]])\r\n",
      "  data_time: 0.0089  time: 0.1869\r\n",
      "11/22 03:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][100/241]  lr: 1.0000e-04  eta: 1:26:53  time: 0.5848  data_time: 0.0012  memory: 10877  loss: 0.0197\r\n",
      "11/22 03:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][200/241]  lr: 1.0000e-04  eta: 1:25:42  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0209\r\n",
      "11/22 03:36:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][100/241]  lr: 1.0000e-04  eta: 1:24:02  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0196\r\n",
      "11/22 03:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:38:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][200/241]  lr: 1.0000e-04  eta: 1:22:52  time: 0.5851  data_time: 0.0012  memory: 10877  loss: 0.0221\r\n",
      "11/22 03:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:39:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][100/241]  lr: 1.0000e-04  eta: 1:21:15  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0211\r\n",
      "11/22 03:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][200/241]  lr: 1.0000e-04  eta: 1:20:06  time: 0.5846  data_time: 0.0012  memory: 10877  loss: 0.0164\r\n",
      "11/22 03:41:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][100/241]  lr: 1.0000e-04  eta: 1:18:30  time: 0.5850  data_time: 0.0012  memory: 10877  loss: 0.0177\r\n",
      "11/22 03:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][200/241]  lr: 1.0000e-04  eta: 1:17:22  time: 0.5852  data_time: 0.0012  memory: 10877  loss: 0.0242\r\n",
      "11/22 03:43:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:44:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][100/241]  lr: 1.0000e-04  eta: 1:15:48  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0175\r\n",
      "11/22 03:45:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][200/241]  lr: 1.0000e-04  eta: 1:14:41  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0238\r\n",
      "11/22 03:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20 epochs\r\n",
      "11/22 03:45:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][35/35]    accuracy/top1: 97.7113  confusion_matrix/result: \r\n",
      "tensor([[  42,    9,    0,    0,    4,    3],\r\n",
      "        [   6,   25,    0,    0,    1,    1],\r\n",
      "        [   0,    2,   17,    7,    0,    1],\r\n",
      "        [   0,    0,    1,   15,    0,    0],\r\n",
      "        [   2,    0,    0,    0, 4173,    7],\r\n",
      "        [   2,    1,    0,    0,   54,   40]])\r\n",
      "  data_time: 0.0077  time: 0.1856\r\n",
      "11/22 03:46:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][100/241]  lr: 1.0000e-04  eta: 1:13:08  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0217\r\n",
      "11/22 03:47:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:47:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][200/241]  lr: 1.0000e-04  eta: 1:12:02  time: 0.5850  data_time: 0.0012  memory: 10877  loss: 0.0135\r\n",
      "11/22 03:48:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][100/241]  lr: 1.0000e-04  eta: 1:10:29  time: 0.5853  data_time: 0.0011  memory: 10877  loss: 0.0186\r\n",
      "11/22 03:50:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][200/241]  lr: 1.0000e-04  eta: 1:09:24  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0178\r\n",
      "11/22 03:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:51:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][100/241]  lr: 1.0000e-04  eta: 1:07:52  time: 0.5851  data_time: 0.0012  memory: 10877  loss: 0.0206\r\n",
      "11/22 03:52:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][200/241]  lr: 1.0000e-04  eta: 1:06:48  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0174\r\n",
      "11/22 03:52:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][100/241]  lr: 1.0000e-04  eta: 1:05:17  time: 0.5846  data_time: 0.0011  memory: 10877  loss: 0.0227\r\n",
      "11/22 03:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][200/241]  lr: 1.0000e-04  eta: 1:04:13  time: 0.5845  data_time: 0.0011  memory: 10877  loss: 0.0189\r\n",
      "11/22 03:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][100/241]  lr: 1.0000e-04  eta: 1:02:43  time: 0.5846  data_time: 0.0010  memory: 10877  loss: 0.0197\r\n",
      "11/22 03:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][200/241]  lr: 1.0000e-04  eta: 1:01:39  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0153\r\n",
      "11/22 03:57:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:57:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 03:57:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][35/35]    accuracy/top1: 97.8699  confusion_matrix/result: \r\n",
      "tensor([[  44,   11,    0,    0,    0,    3],\r\n",
      "        [   6,   26,    0,    0,    0,    1],\r\n",
      "        [   0,    1,   19,    5,    0,    2],\r\n",
      "        [   0,    0,    0,   15,    1,    0],\r\n",
      "        [   1,    0,    0,    0, 4159,   22],\r\n",
      "        [   2,    0,    1,    0,   38,   56]])\r\n",
      "  data_time: 0.0210  time: 0.1991\r\n",
      "11/22 03:58:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][100/241]  lr: 1.0000e-05  eta: 1:00:09  time: 0.5845  data_time: 0.0011  memory: 10877  loss: 0.0138\r\n",
      "11/22 03:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][200/241]  lr: 1.0000e-05  eta: 0:59:06  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0186\r\n",
      "11/22 04:00:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][100/241]  lr: 1.0000e-05  eta: 0:57:37  time: 0.5850  data_time: 0.0011  memory: 10877  loss: 0.0130\r\n",
      "11/22 04:01:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][200/241]  lr: 1.0000e-05  eta: 0:56:34  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0159\r\n",
      "11/22 04:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:03:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][100/241]  lr: 1.0000e-05  eta: 0:55:06  time: 0.5852  data_time: 0.0011  memory: 10877  loss: 0.0135\r\n",
      "11/22 04:04:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][200/241]  lr: 1.0000e-05  eta: 0:54:03  time: 0.5851  data_time: 0.0011  memory: 10877  loss: 0.0196\r\n",
      "11/22 04:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:05:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][100/241]  lr: 1.0000e-05  eta: 0:52:35  time: 0.5850  data_time: 0.0012  memory: 10877  loss: 0.0132\r\n",
      "11/22 04:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][200/241]  lr: 1.0000e-05  eta: 0:51:33  time: 0.5847  data_time: 0.0011  memory: 10877  loss: 0.0173\r\n",
      "11/22 04:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][100/241]  lr: 1.0000e-05  eta: 0:50:05  time: 0.5845  data_time: 0.0011  memory: 10877  loss: 0.0169\r\n",
      "11/22 04:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][200/241]  lr: 1.0000e-05  eta: 0:49:03  time: 0.5856  data_time: 0.0012  memory: 10877  loss: 0.0142\r\n",
      "11/22 04:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\r\n",
      "11/22 04:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][35/35]    accuracy/top1: 97.8246  confusion_matrix/result: \r\n",
      "tensor([[  43,   13,    1,    0,    0,    1],\r\n",
      "        [   7,   26,    0,    0,    0,    0],\r\n",
      "        [   0,    2,   22,    2,    0,    1],\r\n",
      "        [   0,    0,    2,   14,    0,    0],\r\n",
      "        [   3,    0,    0,    0, 4151,   28],\r\n",
      "        [   4,    1,    0,    0,   31,   61]])\r\n",
      "  data_time: 0.0103  time: 0.1982\r\n",
      "11/22 04:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][100/241]  lr: 1.0000e-05  eta: 0:47:36  time: 0.5851  data_time: 0.0010  memory: 10877  loss: 0.0123\r\n",
      "11/22 04:11:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][200/241]  lr: 1.0000e-05  eta: 0:46:34  time: 0.5851  data_time: 0.0011  memory: 10877  loss: 0.0138\r\n",
      "11/22 04:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:12:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][100/241]  lr: 1.0000e-05  eta: 0:45:07  time: 0.5844  data_time: 0.0011  memory: 10877  loss: 0.0129\r\n",
      "11/22 04:13:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][200/241]  lr: 1.0000e-05  eta: 0:44:05  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0145\r\n",
      "11/22 04:14:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:15:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][100/241]  lr: 1.0000e-05  eta: 0:42:39  time: 0.5851  data_time: 0.0012  memory: 10877  loss: 0.0089\r\n",
      "11/22 04:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][200/241]  lr: 1.0000e-05  eta: 0:41:37  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0193\r\n",
      "11/22 04:16:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][100/241]  lr: 1.0000e-05  eta: 0:40:11  time: 0.5848  data_time: 0.0012  memory: 10877  loss: 0.0192\r\n",
      "11/22 04:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][200/241]  lr: 1.0000e-05  eta: 0:39:10  time: 0.5853  data_time: 0.0012  memory: 10877  loss: 0.0144\r\n",
      "11/22 04:18:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][100/241]  lr: 1.0000e-05  eta: 0:37:43  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0135\r\n",
      "11/22 04:20:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][200/241]  lr: 1.0000e-05  eta: 0:36:42  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0183\r\n",
      "11/22 04:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][35/35]    accuracy/top1: 97.9379  confusion_matrix/result: \r\n",
      "tensor([[  43,   14,    0,    0,    0,    1],\r\n",
      "        [   7,   26,    0,    0,    0,    0],\r\n",
      "        [   0,    1,   21,    3,    0,    2],\r\n",
      "        [   0,    0,    4,   12,    0,    0],\r\n",
      "        [   3,    0,    0,    0, 4165,   14],\r\n",
      "        [   3,    1,    0,    0,   38,   55]])\r\n",
      "  data_time: 0.0066  time: 0.1843\r\n",
      "11/22 04:22:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][100/241]  lr: 1.0000e-05  eta: 0:35:16  time: 0.5850  data_time: 0.0012  memory: 10877  loss: 0.0136\r\n",
      "11/22 04:23:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][200/241]  lr: 1.0000e-05  eta: 0:34:15  time: 0.5853  data_time: 0.0011  memory: 10877  loss: 0.0140\r\n",
      "11/22 04:23:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][100/241]  lr: 1.0000e-05  eta: 0:32:50  time: 0.5847  data_time: 0.0011  memory: 10877  loss: 0.0132\r\n",
      "11/22 04:25:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][200/241]  lr: 1.0000e-05  eta: 0:31:49  time: 0.5846  data_time: 0.0011  memory: 10877  loss: 0.0139\r\n",
      "11/22 04:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:26:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][100/241]  lr: 1.0000e-05  eta: 0:30:23  time: 0.5844  data_time: 0.0011  memory: 10877  loss: 0.0116\r\n",
      "11/22 04:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][200/241]  lr: 1.0000e-05  eta: 0:29:22  time: 0.5850  data_time: 0.0011  memory: 10877  loss: 0.0180\r\n",
      "11/22 04:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][100/241]  lr: 1.0000e-05  eta: 0:27:57  time: 0.5844  data_time: 0.0011  memory: 10877  loss: 0.0118\r\n",
      "11/22 04:30:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][200/241]  lr: 1.0000e-05  eta: 0:26:56  time: 0.5848  data_time: 0.0010  memory: 10877  loss: 0.0145\r\n",
      "11/22 04:30:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:31:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][100/241]  lr: 1.0000e-05  eta: 0:25:31  time: 0.5849  data_time: 0.0012  memory: 10877  loss: 0.0106\r\n",
      "11/22 04:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][200/241]  lr: 1.0000e-05  eta: 0:24:31  time: 0.5844  data_time: 0.0011  memory: 10877  loss: 0.0156\r\n",
      "11/22 04:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40 epochs\r\n",
      "11/22 04:33:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][35/35]    accuracy/top1: 97.8699  confusion_matrix/result: \r\n",
      "tensor([[  45,   12,    0,    0,    0,    1],\r\n",
      "        [   8,   23,    1,    0,    0,    1],\r\n",
      "        [   0,    1,   21,    3,    0,    2],\r\n",
      "        [   0,    0,    1,   15,    0,    0],\r\n",
      "        [   3,    0,    0,    0, 4159,   20],\r\n",
      "        [   4,    0,    0,    0,   37,   56]])\r\n",
      "  data_time: 0.0074  time: 0.1857\r\n",
      "11/22 04:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][100/241]  lr: 1.0000e-05  eta: 0:23:05  time: 0.5842  data_time: 0.0010  memory: 10877  loss: 0.0116\r\n",
      "11/22 04:35:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][200/241]  lr: 1.0000e-05  eta: 0:22:05  time: 0.5846  data_time: 0.0011  memory: 10877  loss: 0.0162\r\n",
      "11/22 04:35:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][100/241]  lr: 1.0000e-05  eta: 0:20:40  time: 0.5846  data_time: 0.0011  memory: 10877  loss: 0.0161\r\n",
      "11/22 04:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][200/241]  lr: 1.0000e-05  eta: 0:19:40  time: 0.5850  data_time: 0.0012  memory: 10877  loss: 0.0147\r\n",
      "11/22 04:37:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:38:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][100/241]  lr: 1.0000e-05  eta: 0:18:15  time: 0.5852  data_time: 0.0012  memory: 10877  loss: 0.0131\r\n",
      "11/22 04:39:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][200/241]  lr: 1.0000e-05  eta: 0:17:15  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0136\r\n",
      "11/22 04:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:41:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][100/241]  lr: 1.0000e-05  eta: 0:15:50  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0143\r\n",
      "11/22 04:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][200/241]  lr: 1.0000e-05  eta: 0:14:50  time: 0.5846  data_time: 0.0010  memory: 10877  loss: 0.0127\r\n",
      "11/22 04:42:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:43:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][100/241]  lr: 1.0000e-05  eta: 0:13:25  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0097\r\n",
      "11/22 04:44:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][200/241]  lr: 1.0000e-05  eta: 0:12:25  time: 0.5846  data_time: 0.0012  memory: 10877  loss: 0.0122\r\n",
      "11/22 04:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][35/35]    accuracy/top1: 97.8926  confusion_matrix/result: \r\n",
      "tensor([[  44,   13,    0,    0,    0,    1],\r\n",
      "        [   6,   27,    0,    0,    0,    0],\r\n",
      "        [   0,    2,   21,    3,    0,    1],\r\n",
      "        [   0,    0,    1,   15,    0,    0],\r\n",
      "        [   1,    1,    0,    0, 4157,   23],\r\n",
      "        [   4,    1,    0,    0,   36,   56]])\r\n",
      "  data_time: 0.0106  time: 0.1895\r\n",
      "11/22 04:46:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][100/241]  lr: 1.0000e-05  eta: 0:11:01  time: 0.5846  data_time: 0.0011  memory: 10877  loss: 0.0117\r\n",
      "11/22 04:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][200/241]  lr: 1.0000e-05  eta: 0:10:01  time: 0.5848  data_time: 0.0011  memory: 10877  loss: 0.0153\r\n",
      "11/22 04:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:48:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][100/241]  lr: 1.0000e-05  eta: 0:08:36  time: 0.5852  data_time: 0.0012  memory: 10877  loss: 0.0129\r\n",
      "11/22 04:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][200/241]  lr: 1.0000e-05  eta: 0:07:36  time: 0.5847  data_time: 0.0012  memory: 10877  loss: 0.0140\r\n",
      "11/22 04:49:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][100/241]  lr: 1.0000e-05  eta: 0:06:12  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0174\r\n",
      "11/22 04:51:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][200/241]  lr: 1.0000e-05  eta: 0:05:12  time: 0.5849  data_time: 0.0011  memory: 10877  loss: 0.0116\r\n",
      "11/22 04:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][100/241]  lr: 1.0000e-05  eta: 0:03:48  time: 0.5853  data_time: 0.0012  memory: 10877  loss: 0.0123\r\n",
      "11/22 04:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][200/241]  lr: 1.0000e-05  eta: 0:02:48  time: 0.5856  data_time: 0.0012  memory: 10877  loss: 0.0121\r\n",
      "11/22 04:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:55:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][100/241]  lr: 1.0000e-05  eta: 0:01:24  time: 0.5851  data_time: 0.0012  memory: 10877  loss: 0.0104\r\n",
      "11/22 04:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:56:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][200/241]  lr: 1.0000e-05  eta: 0:00:24  time: 0.5851  data_time: 0.0011  memory: 10877  loss: 0.0093\r\n",
      "11/22 04:56:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22_20241122_025455\r\n",
      "11/22 04:56:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 50 epochs\r\n",
      "11/22 04:57:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][35/35]    accuracy/top1: 97.9606  confusion_matrix/result: \r\n",
      "tensor([[  40,   17,    0,    0,    0,    1],\r\n",
      "        [   5,   26,    1,    0,    0,    1],\r\n",
      "        [   0,    1,   21,    3,    0,    2],\r\n",
      "        [   0,    0,    2,   14,    0,    0],\r\n",
      "        [   1,    1,    0,    0, 4164,   16],\r\n",
      "        [   1,    1,    0,    0,   37,   58]])\r\n",
      "  data_time: 0.0082  time: 0.1862\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/train.py /kaggle/input/configs-file/baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95431aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T04:57:12.652189Z",
     "iopub.status.busy": "2024-11-22T04:57:12.651855Z",
     "iopub.status.idle": "2024-11-22T04:59:11.135734Z",
     "shell.execute_reply": "2024-11-22T04:59:11.134822Z"
    },
    "papermill": {
     "duration": 118.539061,
     "end_time": "2024-11-22T04:59:11.138027",
     "exception": false,
     "start_time": "2024-11-22T04:57:12.598966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "11/22 04:57:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 807174538\r\n",
      "    GPU 0: Tesla P100-PCIE-16GB\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.3, V12.3.107\r\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n",
      "    PyTorch: 2.1.2+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX512\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.2+cu121\r\n",
      "    OpenCV: 4.10.0\r\n",
      "    MMEngine: 0.10.5\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 807174538\r\n",
      "    deterministic: False\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "11/22 04:57:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=256)\r\n",
      "batch_size = 128\r\n",
      "data_root = '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(by_epoch=True, interval=10, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=100, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(enable=False, type='VisualizationHook'))\r\n",
      "default_scope = 'mmpretrain'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = '/kaggle/working/experiment_result/epoch_50.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        depth=50,\r\n",
      "        init_cfg=dict(\r\n",
      "            checkpoint=\r\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth',\r\n",
      "            prefix='backbone',\r\n",
      "            type='Pretrained'),\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(3, ),\r\n",
      "        style='pytorch',\r\n",
      "        type='ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        to_rgb=True),\r\n",
      "    head=dict(\r\n",
      "        in_channels=2048,\r\n",
      "        loss=dict(loss_weight=1.0, type='FocalLoss'),\r\n",
      "        num_classes=6,\r\n",
      "        topk=(\r\n",
      "            1,\r\n",
      "            5,\r\n",
      "        ),\r\n",
      "        type='LinearClsHead'),\r\n",
      "    neck=dict(type='GlobalAveragePooling'),\r\n",
      "    type='ImageClassifier')\r\n",
      "optim_wrapper = dict(\r\n",
      "    clip_grad=None,\r\n",
      "    optimizer=dict(lr=0.0001, type='Adam', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "optimizer = dict(_delete_=True, lr=0.0001, type='Adam', weight_decay=0.0001)\r\n",
      "param_scheduler = dict(\r\n",
      "    by_epoch=True, gamma=0.1, milestones=[\r\n",
      "        25,\r\n",
      "    ], type='MultiStepLR')\r\n",
      "randomness = dict(deterministic=False, seed=None)\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=128,\r\n",
      "    collate_fn=dict(type='default_collate'),\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='test_annotation.txt',\r\n",
      "        data_prefix='',\r\n",
      "        data_root=\r\n",
      "        '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(scale=224, type='Resize'),\r\n",
      "            dict(type='PackInputs'),\r\n",
      "        ],\r\n",
      "        type='CustomDataset',\r\n",
      "        with_label=True),\r\n",
      "    num_workers=1,\r\n",
      "    pin_memory=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "test_evaluator = [\r\n",
      "    dict(type='Accuracy'),\r\n",
      "    dict(type='ConfusionMatrix'),\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(scale=224, type='Resize'),\r\n",
      "    dict(type='PackInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=50, type='EpochBasedTrainLoop', val_interval=5)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_size=128,\r\n",
      "    collate_fn=dict(type='default_collate'),\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='train_annotation.txt',\r\n",
      "        data_prefix='',\r\n",
      "        data_root=\r\n",
      "        '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                crop_ratio_range=(\r\n",
      "                    0.08,\r\n",
      "                    1.0,\r\n",
      "                ),\r\n",
      "                scale=224,\r\n",
      "                type='RandomResizedCrop'),\r\n",
      "            dict(\r\n",
      "                direction=[\r\n",
      "                    'horizontal',\r\n",
      "                    'vertical',\r\n",
      "                ],\r\n",
      "                prob=[\r\n",
      "                    0.25,\r\n",
      "                    0.25,\r\n",
      "                ],\r\n",
      "                type='RandomFlip'),\r\n",
      "            dict(type='PackInputs'),\r\n",
      "        ],\r\n",
      "        type='CustomDataset',\r\n",
      "        with_label=True),\r\n",
      "    num_workers=1,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(crop_ratio_range=(\r\n",
      "        0.08,\r\n",
      "        1.0,\r\n",
      "    ), scale=224, type='RandomResizedCrop'),\r\n",
      "    dict(\r\n",
      "        direction=[\r\n",
      "            'horizontal',\r\n",
      "            'vertical',\r\n",
      "        ],\r\n",
      "        prob=[\r\n",
      "            0.25,\r\n",
      "            0.25,\r\n",
      "        ],\r\n",
      "        type='RandomFlip'),\r\n",
      "    dict(type='PackInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=128,\r\n",
      "    collate_fn=dict(type='default_collate'),\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='val_annotation.txt',\r\n",
      "        data_prefix='',\r\n",
      "        data_root=\r\n",
      "        '/kaggle/input/malaria-parasite/final_malaria_full_class_classification_cropped',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(scale=224, type='Resize'),\r\n",
      "            dict(type='PackInputs'),\r\n",
      "        ],\r\n",
      "        type='CustomDataset',\r\n",
      "        with_label=True),\r\n",
      "    num_workers=1,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "val_evaluator = [\r\n",
      "    dict(type='Accuracy'),\r\n",
      "    dict(type='ConfusionMatrix'),\r\n",
      "]\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    type='Visualizer', vis_backends=[\r\n",
      "        dict(type='TensorboardVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = '/kaggle/working/experiment_result'\r\n",
      "\r\n",
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "11/22 04:57:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "11/22 04:57:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) VisualizationHook                  \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) VisualizationHook                  \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "Loads checkpoint by local backend from path: /kaggle/working/experiment_result/epoch_50.pth\r\n",
      "11/22 04:57:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /kaggle/working/experiment_result/epoch_50.pth\r\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\r\n",
      "  self.pid = os.fork()\r\n",
      "11/22 04:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [71/71]    accuracy/top1: 97.7733  confusion_matrix/result: \r\n",
      "tensor([[  88,   22,    1,    0,    1,    6],\r\n",
      "        [   7,   47,    1,    0,    0,    4],\r\n",
      "        [   0,    1,   53,    3,    0,    2],\r\n",
      "        [   0,    1,    2,   42,    0,    0],\r\n",
      "        [   5,    0,    1,    0, 8476,   81],\r\n",
      "        [   4,    0,    0,    0,   59,  120]])\r\n",
      "  data_time: 1.2719  time: 1.4567\r\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py /kaggle/input/configs-file/baseline1_ourdata_focalloss_mmpretrain_kaggle_Nov22.py /kaggle/working/experiment_result/epoch_50.pth"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6074813,
     "sourceId": 9891375,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6081828,
     "sourceId": 9978114,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7693.459441,
   "end_time": "2024-11-22T04:59:11.408481",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T02:50:57.949040",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
